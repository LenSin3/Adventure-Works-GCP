{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [dataproc/region].\n"
     ]
    }
   ],
   "source": [
    "# set region\n",
    "!gcloud config set dataproc/region us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create workflow template\n",
    "!gcloud dataproc workflow-templates create compute-daily-sales-and-returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cluster\n",
    "!gcloud dataproc workflow-templates set-cluster-selector compute-daily-sales-and-returns --cluster-labels goog-dataproc-cluster-name=lpkadvworks-dataproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2023-01-27T18:22:26.212400Z'\n",
      "id: compute-daily-sales-and-returns\n",
      "jobs:\n",
      "- sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/cleanup.sql\n",
      "  stepId: job-cleanup\n",
      "name: projects/dataengongcp/regions/us-central1/workflowTemplates/compute-daily-sales-and-returns\n",
      "placement:\n",
      "  clusterSelector:\n",
      "    clusterLabels:\n",
      "      goog-dataproc-cluster-name: lpkadvworks-dataproc\n",
      "updateTime: '2023-01-27T18:22:59.150236Z'\n",
      "version: 3\n"
     ]
    }
   ],
   "source": [
    "# clean up\n",
    "!gcloud dataproc workflow-templates add-job spark-sql --step-id=job-cleanup --file=gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/cleanup.sql --workflow-template=compute-daily-sales-and-returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark-sql -f gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql -d bucket_name=gs://lpkadvworks -d table_name=customers\n",
    "spark-sql -f gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql -d bucket_name=gs://lpkadvworks -d table_name=territories\n",
    "spark-sql -f gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql -d bucket_name=gs://lpkadvworks -d table_name=categories\n",
    "spark-sql -f gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql -d bucket_name=gs://lpkadvworks -d table_name=subcategories\n",
    "spark-sql -f gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql -d bucket_name=gs://lpkadvworks -d table_name=products\n",
    "spark-sql -f gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql -d bucket_name=gs://lpkadvworks -d table_name=returns\n",
    "spark-sql -f gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql -d bucket_name=gs://lpkadvworks -d table_name=sales\n",
    "\n",
    "\n",
    "\n",
    "spark-sql -f gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/compute_daily_product_revenue.sql -d bucket_name=gs://lpkadvworks\n",
    "spark-sql -f gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/compute_daily_returns_cost.sql -d bucket_name=gs://lpkadvworks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2023-01-27T18:22:26.212400Z'\n",
      "id: compute-daily-sales-and-returns\n",
      "jobs:\n",
      "- sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/cleanup.sql\n",
      "  stepId: job-cleanup\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: customers\n",
      "  stepId: job-convert-customers\n",
      "name: projects/dataengongcp/regions/us-central1/workflowTemplates/compute-daily-sales-and-returns\n",
      "placement:\n",
      "  clusterSelector:\n",
      "    clusterLabels:\n",
      "      goog-dataproc-cluster-name: lpkadvworks-dataproc\n",
      "updateTime: '2023-01-27T18:23:17.145295Z'\n",
      "version: 4\n",
      "createTime: '2023-01-27T18:22:26.212400Z'\n",
      "id: compute-daily-sales-and-returns\n",
      "jobs:\n",
      "- sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/cleanup.sql\n",
      "  stepId: job-cleanup\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: customers\n",
      "  stepId: job-convert-customers\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: territories\n",
      "  stepId: job-convert-territories\n",
      "name: projects/dataengongcp/regions/us-central1/workflowTemplates/compute-daily-sales-and-returns\n",
      "placement:\n",
      "  clusterSelector:\n",
      "    clusterLabels:\n",
      "      goog-dataproc-cluster-name: lpkadvworks-dataproc\n",
      "updateTime: '2023-01-27T18:23:19.071957Z'\n",
      "version: 5\n",
      "createTime: '2023-01-27T18:22:26.212400Z'\n",
      "id: compute-daily-sales-and-returns\n",
      "jobs:\n",
      "- sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/cleanup.sql\n",
      "  stepId: job-cleanup\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: customers\n",
      "  stepId: job-convert-customers\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: territories\n",
      "  stepId: job-convert-territories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: categories\n",
      "  stepId: job-convert-categories\n",
      "name: projects/dataengongcp/regions/us-central1/workflowTemplates/compute-daily-sales-and-returns\n",
      "placement:\n",
      "  clusterSelector:\n",
      "    clusterLabels:\n",
      "      goog-dataproc-cluster-name: lpkadvworks-dataproc\n",
      "updateTime: '2023-01-27T18:23:20.919621Z'\n",
      "version: 6\n",
      "createTime: '2023-01-27T18:22:26.212400Z'\n",
      "id: compute-daily-sales-and-returns\n",
      "jobs:\n",
      "- sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/cleanup.sql\n",
      "  stepId: job-cleanup\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: customers\n",
      "  stepId: job-convert-customers\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: territories\n",
      "  stepId: job-convert-territories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: categories\n",
      "  stepId: job-convert-categories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: subcategories\n",
      "  stepId: job-convert-subcategories\n",
      "name: projects/dataengongcp/regions/us-central1/workflowTemplates/compute-daily-sales-and-returns\n",
      "placement:\n",
      "  clusterSelector:\n",
      "    clusterLabels:\n",
      "      goog-dataproc-cluster-name: lpkadvworks-dataproc\n",
      "updateTime: '2023-01-27T18:23:22.863769Z'\n",
      "version: 7\n",
      "createTime: '2023-01-27T18:22:26.212400Z'\n",
      "id: compute-daily-sales-and-returns\n",
      "jobs:\n",
      "- sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/cleanup.sql\n",
      "  stepId: job-cleanup\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: customers\n",
      "  stepId: job-convert-customers\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: territories\n",
      "  stepId: job-convert-territories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: categories\n",
      "  stepId: job-convert-categories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: subcategories\n",
      "  stepId: job-convert-subcategories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: products\n",
      "  stepId: job-convert-products\n",
      "name: projects/dataengongcp/regions/us-central1/workflowTemplates/compute-daily-sales-and-returns\n",
      "placement:\n",
      "  clusterSelector:\n",
      "    clusterLabels:\n",
      "      goog-dataproc-cluster-name: lpkadvworks-dataproc\n",
      "updateTime: '2023-01-27T18:23:24.841702Z'\n",
      "version: 8\n",
      "createTime: '2023-01-27T18:22:26.212400Z'\n",
      "id: compute-daily-sales-and-returns\n",
      "jobs:\n",
      "- sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/cleanup.sql\n",
      "  stepId: job-cleanup\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: customers\n",
      "  stepId: job-convert-customers\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: territories\n",
      "  stepId: job-convert-territories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: categories\n",
      "  stepId: job-convert-categories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: subcategories\n",
      "  stepId: job-convert-subcategories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: products\n",
      "  stepId: job-convert-products\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: returns\n",
      "  stepId: job-convert-returns\n",
      "name: projects/dataengongcp/regions/us-central1/workflowTemplates/compute-daily-sales-and-returns\n",
      "placement:\n",
      "  clusterSelector:\n",
      "    clusterLabels:\n",
      "      goog-dataproc-cluster-name: lpkadvworks-dataproc\n",
      "updateTime: '2023-01-27T18:23:26.784676Z'\n",
      "version: 9\n",
      "createTime: '2023-01-27T18:22:26.212400Z'\n",
      "id: compute-daily-sales-and-returns\n",
      "jobs:\n",
      "- sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/cleanup.sql\n",
      "  stepId: job-cleanup\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: customers\n",
      "  stepId: job-convert-customers\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: territories\n",
      "  stepId: job-convert-territories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: categories\n",
      "  stepId: job-convert-categories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: subcategories\n",
      "  stepId: job-convert-subcategories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: products\n",
      "  stepId: job-convert-products\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: returns\n",
      "  stepId: job-convert-returns\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: sales\n",
      "  stepId: job-convert-sales\n",
      "name: projects/dataengongcp/regions/us-central1/workflowTemplates/compute-daily-sales-and-returns\n",
      "placement:\n",
      "  clusterSelector:\n",
      "    clusterLabels:\n",
      "      goog-dataproc-cluster-name: lpkadvworks-dataproc\n",
      "updateTime: '2023-01-27T18:23:28.700636Z'\n",
      "version: 10\n"
     ]
    }
   ],
   "source": [
    "# convert files\n",
    "# customers\n",
    "!gcloud dataproc workflow-templates add-job spark-sql --step-id=job-convert-customers --file=gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql --params=bucket_name=gs://lpkadvworks,table_name=customers --workflow-template=compute-daily-sales-and-returns --start-after=job-cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.dataproc.workflow-templates.add-job.spark-sql) INVALID_ARGUMENT: Template contains a duplicate job with step name 'job-convert-territories'\n"
     ]
    }
   ],
   "source": [
    "#territories\n",
    "!gcloud dataproc workflow-templates add-job spark-sql --step-id=job-convert-territories --file=gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql --params=bucket_name=gs://lpkadvworks,table_name=territories --workflow-template=compute-daily-sales-and-returns --start-after=job-cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories\n",
    "!gcloud dataproc workflow-templates add-job spark-sql --step-id=job-convert-categories --file=gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql --params=bucket_name=gs://lpkadvworks,table_name=categories --workflow-template=compute-daily-sales-and-returns --start-after=job-cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subcategories\n",
    "!gcloud dataproc workflow-templates add-job spark-sql --step-id=job-convert-subcategories --file=gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql --params=bucket_name=gs://lpkadvworks,table_name=subcategories --workflow-template=compute-daily-sales-and-returns --start-after=job-cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# products\n",
    "!gcloud dataproc workflow-templates add-job spark-sql --step-id=job-convert-products --file=gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql --params=bucket_name=gs://lpkadvworks,table_name=products --workflow-template=compute-daily-sales-and-returns --start-after=job-cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns\n",
    "!gcloud dataproc workflow-templates add-job spark-sql --step-id=job-convert-returns --file=gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql --params=bucket_name=gs://lpkadvworks,table_name=returns --workflow-template=compute-daily-sales-and-returns --start-after=job-cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales\n",
    "!gcloud dataproc workflow-templates add-job spark-sql --step-id=job-convert-sales --file=gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql --params=bucket_name=gs://lpkadvworks,table_name=sales --workflow-template=compute-daily-sales-and-returns --start-after=job-cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2023-01-27T18:22:26.212400Z'\n",
      "id: compute-daily-sales-and-returns\n",
      "jobs:\n",
      "- sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/cleanup.sql\n",
      "  stepId: job-cleanup\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: customers\n",
      "  stepId: job-convert-customers\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: territories\n",
      "  stepId: job-convert-territories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: categories\n",
      "  stepId: job-convert-categories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: subcategories\n",
      "  stepId: job-convert-subcategories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: products\n",
      "  stepId: job-convert-products\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: returns\n",
      "  stepId: job-convert-returns\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: sales\n",
      "  stepId: job-convert-sales\n",
      "- prerequisiteStepIds:\n",
      "  - job-convert-customers\n",
      "  - job-convert-territories\n",
      "  - job-convert-categories\n",
      "  - job-convert-subcategories\n",
      "  - job-convert-products\n",
      "  - job-convert-returns\n",
      "  - job-convert-sales\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/compute_daily_product_revenue.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "  stepId: job-daily-sales-revenue\n",
      "name: projects/dataengongcp/regions/us-central1/workflowTemplates/compute-daily-sales-and-returns\n",
      "placement:\n",
      "  clusterSelector:\n",
      "    clusterLabels:\n",
      "      goog-dataproc-cluster-name: lpkadvworks-dataproc\n",
      "updateTime: '2023-01-27T18:27:00.686397Z'\n",
      "version: 11\n"
     ]
    }
   ],
   "source": [
    "# compute daily sales revenue\n",
    "!gcloud dataproc workflow-templates add-job spark-sql --step-id=job-daily-sales-revenue --file=gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/compute_daily_product_revenue.sql --params=bucket_name=gs://lpkadvworks --workflow-template=compute-daily-sales-and-returns --start-after=job-convert-customers,job-convert-territories,job-convert-categories,job-convert-subcategories,job-convert-products,job-convert-returns,job-convert-sales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2023-01-27T18:22:26.212400Z'\n",
      "id: compute-daily-sales-and-returns\n",
      "jobs:\n",
      "- sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/cleanup.sql\n",
      "  stepId: job-cleanup\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: customers\n",
      "  stepId: job-convert-customers\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: territories\n",
      "  stepId: job-convert-territories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: categories\n",
      "  stepId: job-convert-categories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: subcategories\n",
      "  stepId: job-convert-subcategories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: products\n",
      "  stepId: job-convert-products\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: returns\n",
      "  stepId: job-convert-returns\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: sales\n",
      "  stepId: job-convert-sales\n",
      "- prerequisiteStepIds:\n",
      "  - job-convert-customers\n",
      "  - job-convert-territories\n",
      "  - job-convert-categories\n",
      "  - job-convert-subcategories\n",
      "  - job-convert-products\n",
      "  - job-convert-returns\n",
      "  - job-convert-sales\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/compute_daily_product_revenue.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "  stepId: job-daily-sales-revenue\n",
      "- prerequisiteStepIds:\n",
      "  - job-convert-customers\n",
      "  - job-convert-territories\n",
      "  - job-convert-categories\n",
      "  - job-convert-subcategories\n",
      "  - job-convert-products\n",
      "  - job-convert-returns\n",
      "  - job-convert-sales\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/compute_daily_returns_cost.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "  stepId: job-daily-returns-cost\n",
      "name: projects/dataengongcp/regions/us-central1/workflowTemplates/compute-daily-sales-and-returns\n",
      "placement:\n",
      "  clusterSelector:\n",
      "    clusterLabels:\n",
      "      goog-dataproc-cluster-name: lpkadvworks-dataproc\n",
      "updateTime: '2023-01-27T18:27:18.277554Z'\n",
      "version: 12\n"
     ]
    }
   ],
   "source": [
    "# compute daily returns cost\n",
    "!gcloud dataproc workflow-templates add-job spark-sql --step-id=job-daily-returns-cost --file=gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/compute_daily_returns_cost.sql --params=bucket_name=gs://lpkadvworks --workflow-template=compute-daily-sales-and-returns --start-after=job-convert-customers,job-convert-territories,job-convert-categories,job-convert-subcategories,job-convert-products,job-convert-returns,job-convert-sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2023-01-27T18:22:26.212400Z'\n",
      "id: compute-daily-sales-and-returns\n",
      "jobs:\n",
      "- sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/cleanup.sql\n",
      "  stepId: job-cleanup\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: customers\n",
      "  stepId: job-convert-customers\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: territories\n",
      "  stepId: job-convert-territories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: categories\n",
      "  stepId: job-convert-categories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: subcategories\n",
      "  stepId: job-convert-subcategories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: products\n",
      "  stepId: job-convert-products\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: returns\n",
      "  stepId: job-convert-returns\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: sales\n",
      "  stepId: job-convert-sales\n",
      "- prerequisiteStepIds:\n",
      "  - job-convert-customers\n",
      "  - job-convert-territories\n",
      "  - job-convert-categories\n",
      "  - job-convert-subcategories\n",
      "  - job-convert-products\n",
      "  - job-convert-returns\n",
      "  - job-convert-sales\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/compute_daily_product_revenue.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "  stepId: job-daily-sales-revenue\n",
      "- prerequisiteStepIds:\n",
      "  - job-convert-customers\n",
      "  - job-convert-territories\n",
      "  - job-convert-categories\n",
      "  - job-convert-subcategories\n",
      "  - job-convert-products\n",
      "  - job-convert-returns\n",
      "  - job-convert-sales\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/compute_daily_returns_cost.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "  stepId: job-daily-returns-cost\n",
      "name: projects/dataengongcp/regions/us-central1/workflowTemplates/compute-daily-sales-and-returns\n",
      "placement:\n",
      "  clusterSelector:\n",
      "    clusterLabels:\n",
      "      goog-dataproc-cluster-name: lpkadvworks-dataproc\n",
      "updateTime: '2023-01-27T18:27:18.277554Z'\n",
      "version: 12\n"
     ]
    }
   ],
   "source": [
    "# describe workflow template\n",
    "!gcloud dataproc workflow-templates describe compute-daily-sales-and-returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs:\n",
      "- sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/cleanup.sql\n",
      "  stepId: job-cleanup\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: customers\n",
      "  stepId: job-convert-customers\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: territories\n",
      "  stepId: job-convert-territories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: categories\n",
      "  stepId: job-convert-categories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: subcategories\n",
      "  stepId: job-convert-subcategories\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: products\n",
      "  stepId: job-convert-products\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: returns\n",
      "  stepId: job-convert-returns\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "      table_name: sales\n",
      "  stepId: job-convert-sales\n",
      "- prerequisiteStepIds:\n",
      "  - job-convert-customers\n",
      "  - job-convert-territories\n",
      "  - job-convert-categories\n",
      "  - job-convert-subcategories\n",
      "  - job-convert-products\n",
      "  - job-convert-returns\n",
      "  - job-convert-sales\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/compute_daily_product_revenue.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "  stepId: job-daily-sales-revenue\n",
      "- prerequisiteStepIds:\n",
      "  - job-convert-customers\n",
      "  - job-convert-territories\n",
      "  - job-convert-categories\n",
      "  - job-convert-subcategories\n",
      "  - job-convert-products\n",
      "  - job-convert-returns\n",
      "  - job-convert-sales\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://lpkadvworks/scripts/yearly_subcategory_sales/pandas_spark_sql/compute_daily_returns_cost.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://lpkadvworks\n",
      "  stepId: job-daily-returns-cost\n",
      "placement:\n",
      "  clusterSelector:\n",
      "    clusterLabels:\n",
      "      goog-dataproc-cluster-name: lpkadvworks-dataproc\n"
     ]
    }
   ],
   "source": [
    "# export workflow template\n",
    "!gcloud dataproc workflow-templates export compute-daily-sales-and-returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting on operation [projects/dataengongcp/regions/us-central1/operations/967a0cdc-f7bc-3eee-8d69-e1b495885623].\n",
      "WorkflowTemplate [compute-daily-sales-and-returns] RUNNING\n",
      "Job ID job-cleanup-lgpmrz52smybg RUNNING\n",
      "Job ID job-cleanup-lgpmrz52smybg COMPLETED\n",
      "Job ID job-convert-customers-lgpmrz52smybg RUNNING\n",
      "Job ID job-convert-territories-lgpmrz52smybg RUNNING\n",
      "Job ID job-convert-categories-lgpmrz52smybg RUNNING\n",
      "Job ID job-convert-subcategories-lgpmrz52smybg RUNNING\n",
      "Job ID job-convert-products-lgpmrz52smybg RUNNING\n",
      "Job ID job-convert-returns-lgpmrz52smybg RUNNING\n",
      "Job ID job-convert-sales-lgpmrz52smybg RUNNING\n",
      "Job ID job-convert-customers-lgpmrz52smybg COMPLETED\n",
      "Job ID job-convert-territories-lgpmrz52smybg COMPLETED\n",
      "Job ID job-convert-categories-lgpmrz52smybg COMPLETED\n",
      "Job ID job-convert-subcategories-lgpmrz52smybg COMPLETED\n",
      "Job ID job-convert-products-lgpmrz52smybg COMPLETED\n",
      "Job ID job-convert-returns-lgpmrz52smybg COMPLETED\n",
      "Job ID job-convert-sales-lgpmrz52smybg COMPLETED\n",
      "Job ID job-daily-sales-revenue-lgpmrz52smybg RUNNING\n",
      "Job ID job-daily-returns-cost-lgpmrz52smybg RUNNING\n",
      "WorkflowTemplate [compute-daily-sales-and-returns] DONE\n",
      "Job ID job-daily-sales-revenue-lgpmrz52smybg COMPLETED\n",
      "Job ID job-daily-returns-cost-lgpmrz52smybg COMPLETED\n"
     ]
    }
   ],
   "source": [
    "# instatntiate and run the workflow\n",
    "!gcloud dataproc workflow-templates instantiate compute-daily-sales-and-returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: 967a0cdc-f7bc-3eee-8d69-e1b495885623\n",
      "TIMESTAMP: 2023-01-27T18:33:07.475269Z\n",
      "TYPE: WORKFLOW\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: fb1371ee-6b5c-46ed-aa62-298011f3e7f5\n",
      "TIMESTAMP: 2023-01-27T17:02:54.430986Z\n",
      "TYPE: START\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: d8e4ee67-928d-40e2-a7ea-6edd320366c2\n",
      "TIMESTAMP: 2023-01-27T01:45:11.467902Z\n",
      "TYPE: STOP\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: a8d266ea-13f9-499f-bf48-f902813badda\n",
      "TIMESTAMP: 2023-01-26T17:55:11.337892Z\n",
      "TYPE: START\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: dd5b7cbe-afda-4985-8e12-67f7d41af527\n",
      "TIMESTAMP: 2023-01-26T08:24:52.968845Z\n",
      "TYPE: STOP\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: 127a4c13-bc86-4ee3-b44f-dcfaec3ecfb5\n",
      "TIMESTAMP: 2023-01-26T08:04:07.736009Z\n",
      "TYPE: START\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: d2a0751f-ca92-4982-973b-6eb4cb64d017\n",
      "TIMESTAMP: 2023-01-26T01:02:03.981757Z\n",
      "TYPE: STOP\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: 32048360-8577-44d7-8432-de78adf4366f\n",
      "TIMESTAMP: 2023-01-25T17:28:59.936034Z\n",
      "TYPE: START\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: 90aa2b66-e240-4fe6-9a82-9fe49525ac74\n",
      "TIMESTAMP: 2023-01-25T10:10:39.297876Z\n",
      "TYPE: STOP\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: d48bc912-2cc6-4b61-bc8a-421b78733432\n",
      "TIMESTAMP: 2023-01-25T09:05:52.107397Z\n",
      "TYPE: START\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: 5244ec2a-c081-4dda-9c60-8bc9615be83a\n",
      "TIMESTAMP: 2023-01-22T12:10:09.476895Z\n",
      "TYPE: STOP\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: d0369210-df9a-440a-aaf0-9d04b0274604\n",
      "TIMESTAMP: 2023-01-22T06:53:09.835142Z\n",
      "TYPE: START\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: cd7083fd-be2c-437b-bfd6-6fa55c200dce\n",
      "TIMESTAMP: 2023-01-22T06:48:42.604699Z\n",
      "TYPE: STOP\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: 6ff6293b-225c-4f6a-aadd-be6e44e41941\n",
      "TIMESTAMP: 2023-01-22T04:24:23.845879Z\n",
      "TYPE: START\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: 8eaa4c2b-4078-46f0-8060-f08371098d3c\n",
      "TIMESTAMP: 2023-01-18T08:43:52.084489Z\n",
      "TYPE: STOP\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: 4739fb0f-74dd-40a7-a930-6791d417345d\n",
      "TIMESTAMP: 2023-01-18T04:58:43.664851Z\n",
      "TYPE: START\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: da7670d7-7497-4d7b-8b3c-c931fb4c8658\n",
      "TIMESTAMP: 2023-01-17T10:08:38.564880Z\n",
      "TYPE: STOP\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: 7ef15882-c432-426d-b889-50d99131554d\n",
      "TIMESTAMP: 2023-01-17T06:25:28.659932Z\n",
      "TYPE: START\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: 98842ebb-538e-47a9-a812-3ca8ce577a72\n",
      "TIMESTAMP: 2023-01-17T06:22:17.315242Z\n",
      "TYPE: STOP\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: 4ddfd4a4-92de-4306-94a6-b325af369e6d\n",
      "TIMESTAMP: 2023-01-17T05:51:10.821114Z\n",
      "TYPE: CREATE\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: 3\n",
      "\n",
      "NAME: 94c7ea92-b6c8-4254-9225-c24ac0a40f75\n",
      "TIMESTAMP: 2023-01-15T04:13:45.531574Z\n",
      "TYPE: DELETE\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: ebfdcb52-89e1-40ea-b9b8-e1f6a39546a6\n",
      "TIMESTAMP: 2023-01-15T03:31:25.138419Z\n",
      "TYPE: WORKFLOW\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: 4b41fc75-8b23-36c3-8c6f-8f5b98508aad\n",
      "TIMESTAMP: 2023-01-14T21:21:05.720539Z\n",
      "TYPE: WORKFLOW\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: 3a43300f-56e4-4def-9aae-4f834c25203e\n",
      "TIMESTAMP: 2023-01-14T08:54:53.253592Z\n",
      "TYPE: START\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: 68b7ad23-bf0b-40e1-8879-cfe876c5330f\n",
      "TIMESTAMP: 2023-01-09T09:16:37.116722Z\n",
      "TYPE: STOP\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n",
      "\n",
      "NAME: c0b80a96-a3ea-3b1c-ab4a-743da10c978a\n",
      "TIMESTAMP: 2023-01-09T09:08:16.648325Z\n",
      "TYPE: WORKFLOW\n",
      "STATE: DONE\n",
      "ERROR: \n",
      "WARNINGS: \n"
     ]
    }
   ],
   "source": [
    "# run and validate workflow runs\n",
    "!gcloud dataproc operations list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleted [967a0cdc-f7bc-3eee-8d69-e1b495885623].\n",
      "Deleted [fb1371ee-6b5c-46ed-aa62-298011f3e7f5].\n",
      "Deleted [d8e4ee67-928d-40e2-a7ea-6edd320366c2].\n",
      "Deleted [a8d266ea-13f9-499f-bf48-f902813badda].\n",
      "Deleted [dd5b7cbe-afda-4985-8e12-67f7d41af527].\n",
      "Deleted [127a4c13-bc86-4ee3-b44f-dcfaec3ecfb5].\n",
      "Deleted [d2a0751f-ca92-4982-973b-6eb4cb64d017].\n",
      "Deleted [32048360-8577-44d7-8432-de78adf4366f].\n",
      "Deleted [90aa2b66-e240-4fe6-9a82-9fe49525ac74].\n",
      "Deleted [d48bc912-2cc6-4b61-bc8a-421b78733432].\n",
      "Deleted [5244ec2a-c081-4dda-9c60-8bc9615be83a].\n",
      "Deleted [d0369210-df9a-440a-aaf0-9d04b0274604].\n",
      "Deleted [cd7083fd-be2c-437b-bfd6-6fa55c200dce].\n",
      "Deleted [6ff6293b-225c-4f6a-aadd-be6e44e41941].\n",
      "Deleted [8eaa4c2b-4078-46f0-8060-f08371098d3c].\n",
      "Deleted [4739fb0f-74dd-40a7-a930-6791d417345d].\n",
      "Deleted [da7670d7-7497-4d7b-8b3c-c931fb4c8658].\n",
      "Deleted [7ef15882-c432-426d-b889-50d99131554d].\n",
      "Deleted [98842ebb-538e-47a9-a812-3ca8ce577a72].\n",
      "Deleted [4ddfd4a4-92de-4306-94a6-b325af369e6d].\n",
      "Deleted [94c7ea92-b6c8-4254-9225-c24ac0a40f75].\n",
      "Deleted [ebfdcb52-89e1-40ea-b9b8-e1f6a39546a6].\n",
      "Deleted [4b41fc75-8b23-36c3-8c6f-8f5b98508aad].\n",
      "Deleted [3a43300f-56e4-4def-9aae-4f834c25203e].\n",
      "Deleted [68b7ad23-bf0b-40e1-8879-cfe876c5330f].\n",
      "Deleted [c0b80a96-a3ea-3b1c-ab4a-743da10c978a].\n"
     ]
    }
   ],
   "source": [
    "# delete operations\n",
    "!gcloud dataproc operations delete 967a0cdc-f7bc-3eee-8d69-e1b495885623 --quiet\n",
    "!gcloud dataproc operations delete fb1371ee-6b5c-46ed-aa62-298011f3e7f5 --quiet\n",
    "!gcloud dataproc operations delete d8e4ee67-928d-40e2-a7ea-6edd320366c2 --quiet\n",
    "!gcloud dataproc operations delete a8d266ea-13f9-499f-bf48-f902813badda --quiet\n",
    "!gcloud dataproc operations delete dd5b7cbe-afda-4985-8e12-67f7d41af527 --quiet\n",
    "!gcloud dataproc operations delete 127a4c13-bc86-4ee3-b44f-dcfaec3ecfb5 --quiet\n",
    "!gcloud dataproc operations delete d2a0751f-ca92-4982-973b-6eb4cb64d017 --quiet\n",
    "!gcloud dataproc operations delete 32048360-8577-44d7-8432-de78adf4366f --quiet\n",
    "!gcloud dataproc operations delete 90aa2b66-e240-4fe6-9a82-9fe49525ac74 --quiet\n",
    "!gcloud dataproc operations delete d48bc912-2cc6-4b61-bc8a-421b78733432 --quiet\n",
    "!gcloud dataproc operations delete 5244ec2a-c081-4dda-9c60-8bc9615be83a --quiet\n",
    "!gcloud dataproc operations delete d0369210-df9a-440a-aaf0-9d04b0274604 --quiet\n",
    "!gcloud dataproc operations delete cd7083fd-be2c-437b-bfd6-6fa55c200dce --quiet\n",
    "!gcloud dataproc operations delete 6ff6293b-225c-4f6a-aadd-be6e44e41941 --quiet\n",
    "!gcloud dataproc operations delete 8eaa4c2b-4078-46f0-8060-f08371098d3c --quiet\n",
    "!gcloud dataproc operations delete 4739fb0f-74dd-40a7-a930-6791d417345d --quiet\n",
    "!gcloud dataproc operations delete da7670d7-7497-4d7b-8b3c-c931fb4c8658 --quiet\n",
    "!gcloud dataproc operations delete 7ef15882-c432-426d-b889-50d99131554d --quiet\n",
    "!gcloud dataproc operations delete 98842ebb-538e-47a9-a812-3ca8ce577a72 --quiet\n",
    "!gcloud dataproc operations delete 4ddfd4a4-92de-4306-94a6-b325af369e6d --quiet\n",
    "!gcloud dataproc operations delete 94c7ea92-b6c8-4254-9225-c24ac0a40f75 --quiet\n",
    "!gcloud dataproc operations delete ebfdcb52-89e1-40ea-b9b8-e1f6a39546a6 --quiet\n",
    "!gcloud dataproc operations delete 4b41fc75-8b23-36c3-8c6f-8f5b98508aad --quiet\n",
    "!gcloud dataproc operations delete 3a43300f-56e4-4def-9aae-4f834c25203e --quiet\n",
    "!gcloud dataproc operations delete 68b7ad23-bf0b-40e1-8879-cfe876c5330f --quiet\n",
    "!gcloud dataproc operations delete c0b80a96-a3ea-3b1c-ab4a-743da10c978a --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: true\n",
      "driverControlFilesUri: gs://dataproc-staging-us-central1-601008774133-b4r9uivd/google-cloud-dataproc-metainfo/31c9b2a8-7d1c-46d9-8b4a-d3f263c131ea/jobs/3fc81f64c8884785a541cd04b808b808/\n",
      "driverOutputResourceUri: gs://dataproc-staging-us-central1-601008774133-b4r9uivd/google-cloud-dataproc-metainfo/31c9b2a8-7d1c-46d9-8b4a-d3f263c131ea/jobs/3fc81f64c8884785a541cd04b808b808/driveroutput\n",
      "jobUuid: dead3ce3-d46a-3dc7-a0de-3adbb7b0a3d1\n",
      "placement:\n",
      "  clusterName: lpkadvworks-dataproc\n",
      "  clusterUuid: 31c9b2a8-7d1c-46d9-8b4a-d3f263c131ea\n",
      "reference:\n",
      "  jobId: 3fc81f64c8884785a541cd04b808b808\n",
      "  projectId: dataengongcp\n",
      "sparkSqlJob:\n",
      "  queryList:\n",
      "    queries:\n",
      "    - SHOW databases\n",
      "status:\n",
      "  state: DONE\n",
      "  stateStartTime: '2023-01-27T18:58:40.778924Z'\n",
      "statusHistory:\n",
      "- state: PENDING\n",
      "  stateStartTime: '2023-01-27T18:58:19.842026Z'\n",
      "- state: SETUP_DONE\n",
      "  stateStartTime: '2023-01-27T18:58:19.892977Z'\n",
      "- details: Agent reported job success\n",
      "  state: RUNNING\n",
      "  stateStartTime: '2023-01-27T18:58:20.172509Z'\n",
      "yarnApplications:\n",
      "- name: SparkSQL::10.128.0.8\n",
      "  progress: 1.0\n",
      "  state: FINISHED\n",
      "  trackingUrl: http://lpkadvworks-dataproc-m:8088/proxy/application_1674839038332_0011/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [3fc81f64c8884785a541cd04b808b808] submitted.\n",
      "Waiting for job output...\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n",
      "23/01/27 18:58:25 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "23/01/27 18:58:25 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "23/01/27 18:58:25 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "23/01/27 18:58:25 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "Spark master: yarn, Application Id: application_1674839038332_0011\n",
      "default\n",
      "returns_gold_db\n",
      "sales_bronze_db\n",
      "sales_gold_db\n",
      "Time taken: 4.292 seconds, Fetched 4 row(s)\n",
      "Job [3fc81f64c8884785a541cd04b808b808] finished successfully.\n"
     ]
    }
   ],
   "source": [
    "# validate\n",
    "!gcloud dataproc jobs submit spark-sql --cluster=lpkadvworks-dataproc -e \"SHOW databases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [20243e57db53460abb75e4b60187fef6] submitted.\n",
      "Waiting for job output...\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n",
      "23/01/27 19:02:17 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "23/01/27 19:02:17 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "23/01/27 19:02:17 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "23/01/27 19:02:17 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "Spark master: yarn, Application Id: application_1674839038332_0012\n",
      "Time taken: 3.728 seconds\n",
      "sales_bronze_db\tcategories\tfalse\n",
      "sales_bronze_db\tcustomers\tfalse\n",
      "sales_bronze_db\tproducts\tfalse\n",
      "sales_bronze_db\treturns\tfalse\n",
      "sales_bronze_db\tsales\tfalse\n",
      "sales_bronze_db\tsubcategories\tfalse\n",
      "sales_bronze_db\tterritories\tfalse\n",
      "Time taken: 0.531 seconds, Fetched 7 row(s)\n",
      "Job [20243e57db53460abb75e4b60187fef6] finished successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: true\n",
      "driverControlFilesUri: gs://dataproc-staging-us-central1-601008774133-b4r9uivd/google-cloud-dataproc-metainfo/31c9b2a8-7d1c-46d9-8b4a-d3f263c131ea/jobs/20243e57db53460abb75e4b60187fef6/\n",
      "driverOutputResourceUri: gs://dataproc-staging-us-central1-601008774133-b4r9uivd/google-cloud-dataproc-metainfo/31c9b2a8-7d1c-46d9-8b4a-d3f263c131ea/jobs/20243e57db53460abb75e4b60187fef6/driveroutput\n",
      "jobUuid: 095a8ac6-658d-3b09-9c10-b14d127e3441\n",
      "placement:\n",
      "  clusterName: lpkadvworks-dataproc\n",
      "  clusterUuid: 31c9b2a8-7d1c-46d9-8b4a-d3f263c131ea\n",
      "reference:\n",
      "  jobId: 20243e57db53460abb75e4b60187fef6\n",
      "  projectId: dataengongcp\n",
      "sparkSqlJob:\n",
      "  queryList:\n",
      "    queries:\n",
      "    - USE sales_bronze_db;SHOW tables\n",
      "status:\n",
      "  state: DONE\n",
      "  stateStartTime: '2023-01-27T19:02:31.954779Z'\n",
      "statusHistory:\n",
      "- state: PENDING\n",
      "  stateStartTime: '2023-01-27T19:02:12.270431Z'\n",
      "- state: SETUP_DONE\n",
      "  stateStartTime: '2023-01-27T19:02:12.321922Z'\n",
      "- details: Agent reported job success\n",
      "  state: RUNNING\n",
      "  stateStartTime: '2023-01-27T19:02:12.601520Z'\n",
      "yarnApplications:\n",
      "- name: SparkSQL::10.128.0.8\n",
      "  progress: 1.0\n",
      "  state: FINISHED\n",
      "  trackingUrl: http://lpkadvworks-dataproc-m:8088/proxy/application_1674839038332_0012/\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs submit spark-sql --cluster=lpkadvworks-dataproc -e \"USE sales_bronze_db;SHOW tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: true\n",
      "driverControlFilesUri: gs://dataproc-staging-us-central1-601008774133-b4r9uivd/google-cloud-dataproc-metainfo/31c9b2a8-7d1c-46d9-8b4a-d3f263c131ea/jobs/2fc1ef0ce3a548f989245c07bee7e6d0/\n",
      "driverOutputResourceUri: gs://dataproc-staging-us-central1-601008774133-b4r9uivd/google-cloud-dataproc-metainfo/31c9b2a8-7d1c-46d9-8b4a-d3f263c131ea/jobs/2fc1ef0ce3a548f989245c07bee7e6d0/driveroutput\n",
      "jobUuid: cd238fc5-fa94-3c86-9683-b0c33121e4c0\n",
      "placement:\n",
      "  clusterName: lpkadvworks-dataproc\n",
      "  clusterUuid: 31c9b2a8-7d1c-46d9-8b4a-d3f263c131ea\n",
      "reference:\n",
      "  jobId: 2fc1ef0ce3a548f989245c07bee7e6d0\n",
      "  projectId: dataengongcp\n",
      "sparkSqlJob:\n",
      "  queryList:\n",
      "    queries:\n",
      "    - USE sales_bronze_db;SELECT * FROM sales LIMIT 10\n",
      "status:\n",
      "  state: DONE\n",
      "  stateStartTime: '2023-01-27T19:06:25.945002Z'\n",
      "statusHistory:\n",
      "- state: PENDING\n",
      "  stateStartTime: '2023-01-27T19:05:57.273106Z'\n",
      "- state: SETUP_DONE\n",
      "  stateStartTime: '2023-01-27T19:05:57.312456Z'\n",
      "- details: Agent reported job success\n",
      "  state: RUNNING\n",
      "  stateStartTime: '2023-01-27T19:05:57.568041Z'\n",
      "yarnApplications:\n",
      "- name: SparkSQL::10.128.0.8\n",
      "  progress: 1.0\n",
      "  state: FINISHED\n",
      "  trackingUrl: http://lpkadvworks-dataproc-m:8088/proxy/application_1674839038332_0013/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [2fc1ef0ce3a548f989245c07bee7e6d0] submitted.\n",
      "Waiting for job output...\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n",
      "23/01/27 19:06:02 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "23/01/27 19:06:02 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "23/01/27 19:06:02 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "23/01/27 19:06:02 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "Spark master: yarn, Application Id: application_1674839038332_0013\n",
      "Time taken: 2.992 seconds\n",
      "2015-01-01\t2001-09-21\tSO45080\t332\t14657\t1\t1\t1\n",
      "2015-01-01\t2001-12-05\tSO45079\t312\t29255\t4\t1\t1\n",
      "2015-01-01\t2001-10-29\tSO45082\t350\t11455\t9\t1\t1\n",
      "2015-01-01\t2001-11-16\tSO45081\t338\t26782\t6\t1\t1\n",
      "2015-01-02\t2001-12-15\tSO45083\t312\t14947\t10\t1\t1\n",
      "2015-01-02\t2001-10-12\tSO45084\t310\t29143\t4\t1\t1\n",
      "2015-01-02\t2001-12-18\tSO45086\t314\t18747\t9\t1\t1\n",
      "2015-01-02\t2001-10-09\tSO45085\t312\t18746\t9\t1\t1\n",
      "2015-01-03\t2001-10-03\tSO45093\t312\t18906\t9\t1\t1\n",
      "2015-01-03\t2001-09-29\tSO45090\t310\t29170\t4\t1\t1\n",
      "Time taken: 6.426 seconds, Fetched 10 row(s)\n",
      "Job [2fc1ef0ce3a548f989245c07bee7e6d0] finished successfully.\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs submit spark-sql --cluster=lpkadvworks-dataproc -e \"USE sales_bronze_db;SELECT * FROM sales LIMIT 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [f5e4d42c1b534bea850483aec4ee7490] submitted.\n",
      "Waiting for job output...\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n",
      "23/01/27 19:06:56 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "23/01/27 19:06:56 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "23/01/27 19:06:56 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "23/01/27 19:06:56 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "Spark master: yarn, Application Id: application_1674839038332_0014\n",
      "Time taken: 3.254 seconds\n",
      "sales_gold_db\tdaily_product_revenue\tfalse\n",
      "Time taken: 0.498 seconds, Fetched 1 row(s)\n",
      "Job [f5e4d42c1b534bea850483aec4ee7490] finished successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: true\n",
      "driverControlFilesUri: gs://dataproc-staging-us-central1-601008774133-b4r9uivd/google-cloud-dataproc-metainfo/31c9b2a8-7d1c-46d9-8b4a-d3f263c131ea/jobs/f5e4d42c1b534bea850483aec4ee7490/\n",
      "driverOutputResourceUri: gs://dataproc-staging-us-central1-601008774133-b4r9uivd/google-cloud-dataproc-metainfo/31c9b2a8-7d1c-46d9-8b4a-d3f263c131ea/jobs/f5e4d42c1b534bea850483aec4ee7490/driveroutput\n",
      "jobUuid: 38adffd4-0f7b-3f6e-964b-70ea3409a5b0\n",
      "placement:\n",
      "  clusterName: lpkadvworks-dataproc\n",
      "  clusterUuid: 31c9b2a8-7d1c-46d9-8b4a-d3f263c131ea\n",
      "reference:\n",
      "  jobId: f5e4d42c1b534bea850483aec4ee7490\n",
      "  projectId: dataengongcp\n",
      "sparkSqlJob:\n",
      "  queryList:\n",
      "    queries:\n",
      "    - USE sales_gold_db;SHOW tables\n",
      "status:\n",
      "  state: DONE\n",
      "  stateStartTime: '2023-01-27T19:07:10.978322Z'\n",
      "statusHistory:\n",
      "- state: PENDING\n",
      "  stateStartTime: '2023-01-27T19:06:50.992299Z'\n",
      "- state: SETUP_DONE\n",
      "  stateStartTime: '2023-01-27T19:06:51.035989Z'\n",
      "- details: Agent reported job success\n",
      "  state: RUNNING\n",
      "  stateStartTime: '2023-01-27T19:06:51.317789Z'\n",
      "yarnApplications:\n",
      "- name: SparkSQL::10.128.0.8\n",
      "  progress: 1.0\n",
      "  state: FINISHED\n",
      "  trackingUrl: http://lpkadvworks-dataproc-m:8088/proxy/application_1674839038332_0014/\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs submit spark-sql --cluster=lpkadvworks-dataproc -e \"USE sales_gold_db;SHOW tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: true"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [7b9f9675591e4937b25dafd79cf3da9f] submitted.\n",
      "Waiting for job output...\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n",
      "23/01/27 19:09:15 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "23/01/27 19:09:15 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "23/01/27 19:09:15 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "23/01/27 19:09:15 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "Spark master: yarn, Application Id: application_1674839038332_0015\n",
      "Time taken: 2.954 seconds\n",
      "2016-12-14\tBikes\t1\tMountain Bikes\t10\t20602.59\n",
      "2016-12-14\tBikes\t3\tTouring Bikes\t7\t11763.33\n",
      "2016-12-14\tAccessories\t37\tTires and Tubes\t60\t851.34\n",
      "2016-12-14\tAccessories\t31\tHelmets\t20\t679.61\n",
      "2016-12-14\tAccessories\t28\tBottles and Cages\t56\t398.44\n",
      "2016-12-14\tClothing\t21\tJerseys\t7\t348.32\n",
      "2016-12-14\tAccessories\t30\tFenders\t12\t263.76\n",
      "2016-12-14\tAccessories\t27\tBike Stands\t1\t159.0\n",
      "2016-12-14\tClothing\t20\tGloves\t6\t141.29\n",
      "2016-12-14\tClothing\t19\tCaps\t15\t129.66\n",
      "Time taken: 6.309 seconds, Fetched 10 row(s)\n",
      "Job [7b9f9675591e4937b25dafd79cf3da9f] finished successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "driverControlFilesUri: gs://dataproc-staging-us-central1-601008774133-b4r9uivd/google-cloud-dataproc-metainfo/31c9b2a8-7d1c-46d9-8b4a-d3f263c131ea/jobs/7b9f9675591e4937b25dafd79cf3da9f/\n",
      "driverOutputResourceUri: gs://dataproc-staging-us-central1-601008774133-b4r9uivd/google-cloud-dataproc-metainfo/31c9b2a8-7d1c-46d9-8b4a-d3f263c131ea/jobs/7b9f9675591e4937b25dafd79cf3da9f/driveroutput\n",
      "jobUuid: f562bec6-5990-379f-940e-2eedf5faefb2\n",
      "placement:\n",
      "  clusterName: lpkadvworks-dataproc\n",
      "  clusterUuid: 31c9b2a8-7d1c-46d9-8b4a-d3f263c131ea\n",
      "reference:\n",
      "  jobId: 7b9f9675591e4937b25dafd79cf3da9f\n",
      "  projectId: dataengongcp\n",
      "sparkSqlJob:\n",
      "  queryList:\n",
      "    queries:\n",
      "    - USE sales_gold_db;SELECT * FROM daily_product_revenue limit 10\n",
      "status:\n",
      "  state: DONE\n",
      "  stateStartTime: '2023-01-27T19:09:36.025478Z'\n",
      "statusHistory:\n",
      "- state: PENDING\n",
      "  stateStartTime: '2023-01-27T19:09:10.383549Z'\n",
      "- state: SETUP_DONE\n",
      "  stateStartTime: '2023-01-27T19:09:10.432238Z'\n",
      "- details: Agent reported job success\n",
      "  state: RUNNING\n",
      "  stateStartTime: '2023-01-27T19:09:10.715147Z'\n",
      "yarnApplications:\n",
      "- name: SparkSQL::10.128.0.8\n",
      "  progress: 1.0\n",
      "  state: FINISHED\n",
      "  trackingUrl: http://lpkadvworks-dataproc-m:8088/proxy/application_1674839038332_0015/\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs submit spark-sql --cluster=lpkadvworks-dataproc -e \"USE sales_gold_db;SELECT * FROM daily_product_revenue limit 10\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advworks-deg-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:41:22) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "426029abc329e5a04b1f11f91aadccfc18968ac65d726452477c5064d503c039"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
